{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Módulo 1 - Utilización, procesamiento y visualiazción de grandes volúmenes de datos.***\n",
    "\n",
    "### Mariana Castro Payns - A01706038\n",
    "\n",
    "DataSet obtenido de: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews?select=Books_rating.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar y establecer variables de entorno\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/mariana/spark/spark-3.2.2-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mariana/spark/spark-3.2.2-bin-hadoop3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buscar e inicializar instalación Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/02 23:24:11 WARN Utils: Your hostname, mariana-Victus resolves to a loopback address: 127.0.1.1; using 192.168.1.74 instead (on interface wlo1)\n",
      "22/11/02 23:24:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/11/02 23:24:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Inicializar sesión de Spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"5g\").appName('Books').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APP Name :Books\n",
      "Master :local[*]\n"
     ]
    }
   ],
   "source": [
    "# Obtener App Name y Master como verificación de la sesión\n",
    "print(\"APP Name :\"+spark.sparkContext.appName)\n",
    "print(\"Master :\"+spark.sparkContext.master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Leer archivo e indicar el encabezado\n",
    "df = spark.read.option('header', 'true').csv('file:///home/mariana/IA/Books_rating.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|1882931173|Its Only Art If I...| null| AVCGYZL8FQQTD|\"Jim of Oz \"\"jim-...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A30TK6U7DNS82R|       Kevin Killian|             10/10|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A3UH4UZ4RSVO82|        John Granger|             10/11|         5.0| 1078790400|Essential for eve...|\"If people become...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A2MVUWT453QH61|\"Roy E. Perry \"\"a...|               7/7|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A22X4XUPKF66MR|\"D. H. Richards \"...|               3/3|         4.0| 1107993600|Good academic ove...|\"Philip Nel - Dr....|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A2F6NONFUDB6UK|              Malvin|               2/2|         4.0| 1127174400|One of America's ...|\"\"\"Dr. Seuss: Ame...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A14OJS0VWMOSWO| Midwest Book Review|               3/4|         5.0| 1100131200|A memorably excel...|Theodor Seuss Gie...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A2RSSXTDZDUSH4|           J. Squire|               0/0|         5.0| 1231200000|Academia At It's ...|\"When I recieved ...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A25MD5I2GUIW6W|\"J. P. HIGBED \"\"b...|               0/0|         5.0| 1209859200|And to think that...|\"Trams (or any pu...|\n",
      "|0826414346|Dr. Seuss: Americ...| null|A3VA4XFS5WNJO3|     Donald Burnside|               3/5|         4.0| 1076371200|Fascinating accou...|As far as I am aw...|\n",
      "|0829814000|Wonderful Worship...|19.40| AZ0IOBU20TBOP|  Rev. Pamela Tinnin|              8/10|         5.0|  991440000|Outstanding Resou...|I just finished t...|\n",
      "|0829814000|Wonderful Worship...|19.40|A373VVEU6Z9M0N|Dr. Terry W. Dorsett|               1/1|         5.0| 1291766400|Small Churches CA...|\"Many small churc...|\n",
      "|0829814000|Wonderful Worship...|19.40| AGKGOH65VTRR4|\"Cynthia L. Lajoy...|               1/1|         5.0| 1248307200|Not Just for Past...|I just finished r...|\n",
      "|0829814000|Wonderful Worship...|19.40| A3OQWLU31BU1Y|       Maxwell Grant|               1/1|         5.0| 1222560000|Small church past...|\"I hadn't been a ...|\n",
      "|0595344550|Whispers of the W...|10.95|A3Q12RK71N74LB|         Book Reader|              7/11|         1.0| 1117065600|            not good|I bought this boo...|\n",
      "|0595344550|Whispers of the W...|10.95|A1E9M6APK30ZAU|           V. Powell|               1/2|         4.0| 1119571200|  Here is my opinion|\"I have to admit,...|\n",
      "|0595344550|Whispers of the W...|10.95| AUR0VA5H0C66C|\"LoveToRead \"\"Act...|               1/2|         1.0| 1119225600|        Buyer beware|\"This is a self-p...|\n",
      "|0595344550|Whispers of the W...|10.95|A1YLDZ3VHR6QPZ|               Clara|               2/4|         5.0| 1115942400| Fall on your knee's|When I first read...|\n",
      "|0595344550|Whispers of the W...|10.95| ACO23CG8K8T77|               Tonya|               5/9|         5.0| 1117065600|      Bravo Veronica|I read the review...|\n",
      "|0595344550|Whispers of the W...|10.95|A1VK81CRRC7MLM|\"missyLou \"\"apple\"\"\"|               1/3|         5.0| 1130025600|           Wonderful|\"I really enjoyed...|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el data frame cargado\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Price: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- profileName: string (nullable = true)\n",
      " |-- review/helpfulness: string (nullable = true)\n",
      " |-- review/score: string (nullable = true)\n",
      " |-- review/time: string (nullable = true)\n",
      " |-- review/summary: string (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el esquema de las variables\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar tipos de datos en columnas necesarias\n",
    "from pyspark.sql.functions import column\n",
    "df = df.withColumn(\"label\", column(\"review/score\").cast('int'))\n",
    "df = df.withColumn(\"Price\", column(\"price\").cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- profileName: string (nullable = true)\n",
      " |-- review/helpfulness: string (nullable = true)\n",
      " |-- review/score: string (nullable = true)\n",
      " |-- review/time: string (nullable = true)\n",
      " |-- review/summary: string (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar tipos de dato\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:============================================>            (17 + 5) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+-------+-----------+------------------+------------+-----------+--------------+-----------+-----+\n",
      "| Id|Title|  Price|User_id|profileName|review/helpfulness|review/score|review/time|review/summary|review/text|label|\n",
      "+---+-----+-------+-------+-----------+------------------+------------+-----------+--------------+-----------+-----+\n",
      "|  0|  208|2519269| 562250|     562250|               367|         130|         27|            65|         43|18064|\n",
      "+---+-----+-------+-------+-----------+------------------+------------+-----------+--------------+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Determinar valores nulos\n",
    "from pyspark.sql.functions import when,lit,count,isnan,col\n",
    "df.select([count(when(isnan(c)|col(c).isNull(),c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar valores nulos\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas relevantes\n",
    "df = df.select(\"id\", \"review/summary\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----+\n",
      "|        id|      review/summary|label|\n",
      "+----------+--------------------+-----+\n",
      "|0829814000|Outstanding Resou...|    5|\n",
      "|0829814000|Small Churches CA...|    5|\n",
      "|0829814000|Not Just for Past...|    5|\n",
      "|0829814000|Small church past...|    5|\n",
      "|0595344550|            not good|    1|\n",
      "|0595344550|  Here is my opinion|    4|\n",
      "|0595344550|        Buyer beware|    1|\n",
      "|0595344550| Fall on your knee's|    5|\n",
      "|0595344550|      Bravo Veronica|    5|\n",
      "|0595344550|           Wonderful|    5|\n",
      "|0595344550|           Awesome !|    5|\n",
      "|0595344550|      Glorious story|    5|\n",
      "|0595344550|         Loved it !!|    5|\n",
      "|0595344550|Five stars it not...|    5|\n",
      "|0595344550|    A FIVE STAR BOOK|    5|\n",
      "|0595344550|Whispers of the W...|    5|\n",
      "|0595344550|Errors, but great...|    4|\n",
      "|0595344550|          The Worst!|    1|\n",
      "|0595344550|The truth about W...|    5|\n",
      "|0595344550|How could someone...|    5|\n",
      "+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar selección\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Configuración de fases del Pipeline - Tokenizer, Hashing, Regresion Lineal\n",
    "tokenizer = Tokenizer(inputCol=\"review/summary\", outputCol=\"words\")\n",
    "hashing = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(maxIter=10)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashing, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
    "\n",
    "# Construcción de un grid de parametros \n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(hashing.numFeatures, [10, 100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Configurar el validador Train-Validation\n",
    "tvs = TrainValidationSplit(estimator=pipeline,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(),\n",
    "                           # 75% de los datos sera utilizado para el training.\n",
    "                           trainRatio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el cross validator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(),\n",
    "                          numFolds=4)  # use 3+ folds in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el data ser\n",
    "train, test = df.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/02 23:24:47 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "22/11/02 23:25:14 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/11/02 23:25:14 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/11/02 23:25:38 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/11/02 23:25:38 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Se ejecuta la validación cruzada para encontrar los mejores parámetros de configuración.\n",
    "cvModel = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id='002412141X', label=3, prediction=4.2465028949999954)\n",
      "Row(id='0027613909', label=5, prediction=4.592399859148961)\n",
      "Row(id='0027613909', label=4, prediction=4.333770252312783)\n",
      "Row(id='0028642627', label=4, prediction=4.197479836883434)\n",
      "Row(id='0028642627', label=1, prediction=3.130675096513806)\n",
      "Row(id='0028642627', label=4, prediction=4.390831234535854)\n",
      "Row(id='002864266X', label=4, prediction=4.15496411229088)\n",
      "Row(id='002864266X', label=5, prediction=4.232667706795603)\n",
      "Row(id='002864266X', label=5, prediction=4.851200454923863)\n",
      "Row(id='002864266X', label=5, prediction=4.418851226719356)\n",
      "Row(id='002864266X', label=3, prediction=3.7111867706606865)\n",
      "Row(id='002864266X', label=4, prediction=3.5630599533900984)\n",
      "Row(id='002864266X', label=2, prediction=3.871474744391057)\n",
      "Row(id='002864266X', label=5, prediction=3.554910418071861)\n",
      "Row(id='0028642686', label=5, prediction=4.891285810891735)\n",
      "Row(id='0030651786', label=5, prediction=4.045040193774086)\n",
      "Row(id='0060005416', label=5, prediction=5.129980865648127)\n",
      "Row(id='0060226064', label=5, prediction=4.348112876804524)\n",
      "Row(id='0060226064', label=3, prediction=3.512606115014804)\n",
      "Row(id='0060226064', label=5, prediction=4.512661706897008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Obtener predicciones con validación cruzada de 20 datos (dado el tamaño del dataset)\n",
    "predictions = cvModel.transform(test)\n",
    "sel = predictions.select(\"id\", \"label\", \"prediction\")\n",
    "for row in sel.take(20):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Buscar la mejor configuración con el Train-Validation\n",
    "tvsModel = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1096:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|        id|label|        prediction|\n",
      "+----------+-----+------------------+\n",
      "|002412141X|    3|4.2465028949999954|\n",
      "|0027613909|    5| 4.592399859148961|\n",
      "|0027613909|    4| 4.333770252312783|\n",
      "|0028642627|    4| 4.197479836883434|\n",
      "|0028642627|    1| 3.130675096513806|\n",
      "|0028642627|    4| 4.390831234535854|\n",
      "|002864266X|    4|  4.15496411229088|\n",
      "|002864266X|    5| 4.232667706795603|\n",
      "|002864266X|    5| 4.851200454923863|\n",
      "|002864266X|    5| 4.418851226719356|\n",
      "|002864266X|    3|3.7111867706606865|\n",
      "|002864266X|    4|3.5630599533900984|\n",
      "|002864266X|    2| 3.871474744391057|\n",
      "|002864266X|    5| 3.554910418071861|\n",
      "|0028642686|    5| 4.891285810891735|\n",
      "|0030651786|    5| 4.045040193774086|\n",
      "|0060005416|    5| 5.129980865648127|\n",
      "|0060226064|    5| 4.348112876804524|\n",
      "|0060226064|    3| 3.512606115014804|\n",
      "|0060226064|    5| 4.512661706897008|\n",
      "+----------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones con los datos de test\n",
    "tvsModel.transform(test).select(\"id\", \"label\", \"prediction\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
